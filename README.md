# Master of Science in Applied Mathematics
This repository contains code for my MSc in Applied Mathematics, which explores the performance of various optimization algorithms on neural networks. Specifically, the performance of quasi-Newton optimization methods on the LeNet-5 convolutional neural network architecture.

## LBFGS Implementation
This Jupyter notebook (LBFGS_Implementation.ipynb) contains my implementation of the Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) optimization algorithm. The notebook includes an overview of the algorithm, a step-by-step implementation, and a comparison of the LBFGS algorithm with other optimization algorithms.

## LBFGS_TR
This Python script (LBFGS_TR.py) contains an implementation of the LBFGS optimization algorithm using trust region (TR) methods. The script includes a brief explanation of the trust-region (TR) method and how it is applied to the LBFGS algorithm.

## SGD with Momentum, RMSProp, Adam
This Jupyter notebook explores the performance of stochastic gradient descent (SGD) with various momentum-based techniques, including Momentum, RMSProp, and Adam. The notebook includes an explanation of each technique, an implementation of the SGD algorithm with each technique, and a comparison of their performance on a simple classification problem.

## Thesis MMA Jose Garcia Nov 2022
This Jupyter notebook (Thesis_MMA_Jose_Garcia_Nov_2022.ipynb) contains my full MMA thesis, including an overview of the problem, a literature review, my methodology, results, and conclusions. The notebook also includes references and appendices with additional information. For more details on the problem being solved, refer to the PDF for a full explanation of the source of the problem. 

## Input MNIST Data
This Python script (input_MNIST_data.py) contains functions for loading and preprocessing the MNIST dataset, which is used throughout my thesis. The script includes functions for downloading the dataset, loading it into memory, and preprocessing it for use in a neural network.
